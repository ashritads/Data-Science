{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ASHRITA CHALLA\n",
    "\"Support Vector Machine Code\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm, datasets\n",
    "import numpy as np\n",
    "import urllib\n",
    "import csv\n",
    "import string\n",
    "import pandas as pd\n",
    "from StringIO import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 32)\n"
     ]
    }
   ],
   "source": [
    "#read data to variable\n",
    "data = pd.read_csv(open(\"C:\\\\Users\\\\Ashrita\\\\Documents\\\\Machine Learning\\\\Data Files\\\\breast_Cancer_Dataset.csv\"), header=0, index_col=False, low_memory=False)\n",
    "print(data.shape)\n",
    "\n",
    "data.columns=pd.Series(list(data.columns.values)).str.replace('_', '')\n",
    "original_headers = list(data.columns.values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['diagnosis' 'radiusmean' 'texturemean' 'perimetermean' 'areamean'\n",
      " 'smoothnessmean' 'compactnessmean' 'concavitymean' 'concave pointsmean'\n",
      " 'symmetrymean' 'fractaldimensionmean' 'radiusse' 'texturese' 'perimeterse'\n",
      " 'arease' 'smoothnessse' 'compactnessse' 'concavityse' 'concave pointsse'\n",
      " 'symmetryse' 'fractaldimensionse' 'radiusworst' 'textureworst'\n",
      " 'perimeterworst' 'areaworst' 'smoothnessworst' 'compactnessworst'\n",
      " 'concavityworst' 'concave pointsworst' 'symmetryworst'\n",
      " 'fractaldimensionworst']\n"
     ]
    }
   ],
   "source": [
    "data = data.replace('M', 1)\n",
    "data = data.replace('B', 0)\n",
    "data = data.drop('id', axis = 1)\n",
    "print(data.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   radiusmean  texturemean  perimetermean  areamean  smoothnessmean  \\\n",
      "0       17.99        10.38         122.80    1001.0         0.11840   \n",
      "1       20.57        17.77         132.90    1326.0         0.08474   \n",
      "2       19.69        21.25         130.00    1203.0         0.10960   \n",
      "3       11.42        20.38          77.58     386.1         0.14250   \n",
      "4       20.29        14.34         135.10    1297.0         0.10030   \n",
      "\n",
      "   compactnessmean  concavitymean  concave pointsmean  symmetrymean  \\\n",
      "0          0.27760         0.3001             0.14710        0.2419   \n",
      "1          0.07864         0.0869             0.07017        0.1812   \n",
      "2          0.15990         0.1974             0.12790        0.2069   \n",
      "3          0.28390         0.2414             0.10520        0.2597   \n",
      "4          0.13280         0.1980             0.10430        0.1809   \n",
      "\n",
      "   fractaldimensionmean          ...            radiusworst  textureworst  \\\n",
      "0               0.07871          ...                  25.38         17.33   \n",
      "1               0.05667          ...                  24.99         23.41   \n",
      "2               0.05999          ...                  23.57         25.53   \n",
      "3               0.09744          ...                  14.91         26.50   \n",
      "4               0.05883          ...                  22.54         16.67   \n",
      "\n",
      "   perimeterworst  areaworst  smoothnessworst  compactnessworst  \\\n",
      "0          184.60     2019.0           0.1622            0.6656   \n",
      "1          158.80     1956.0           0.1238            0.1866   \n",
      "2          152.50     1709.0           0.1444            0.4245   \n",
      "3           98.87      567.7           0.2098            0.8663   \n",
      "4          152.20     1575.0           0.1374            0.2050   \n",
      "\n",
      "   concavityworst  concave pointsworst  symmetryworst  fractaldimensionworst  \n",
      "0          0.7119               0.2654         0.4601                0.11890  \n",
      "1          0.2416               0.1860         0.2750                0.08902  \n",
      "2          0.4504               0.2430         0.3613                0.08758  \n",
      "3          0.6869               0.2575         0.6638                0.17300  \n",
      "4          0.4000               0.1625         0.2364                0.07678  \n",
      "\n",
      "[5 rows x 30 columns]\n",
      "0    1\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "Name: diagnosis, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X_matrix=data.iloc[:,1:]\n",
    "Y=data.iloc[:,0]\n",
    "    \n",
    "print(X_matrix.head(5))\n",
    "print(Y.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scoremodel(data,clf):\n",
    "    X_matrix=data.iloc[:,1:]\n",
    "    Y=data.iloc[:,0]\n",
    "    \n",
    "    \n",
    "    from sklearn.cross_validation import KFold, cross_val_score\n",
    "    \n",
    "    kf = KFold(len(Y), n_folds=5, shuffle=True, random_state=0)\n",
    "    scores = cross_val_score(clf, X_matrix, Y, cv=kf, scoring=\"f1\")\n",
    "    print \"F1: {0:.3f}\".format(np.mean(scores))\n",
    "    scores = cross_val_score(clf, X_matrix, Y, cv=kf, scoring=\"precision\")\n",
    "    print \"Precision: {0:.3f}\".format(np.mean(scores))\n",
    "    scores = cross_val_score(clf, X_matrix, Y, cv=kf, scoring=\"recall\")\n",
    "    print \"Recall: {0:.3f}\".format(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine Scoring using Cross Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ashrita\\Anaconda3\\envs\\py27\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.943\n",
      "Precision: 0.960\n",
      "Recall: 0.929\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC(kernel='linear', C=1.0)\n",
    "print \"Support Vector Machine Scoring using Cross Validation\"\n",
    "scoremodel(data,clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(426, 30)\n",
      "(143, 30)\n"
     ]
    }
   ],
   "source": [
    "#split data into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_holdout, Y_train, Y_holdout=train_test_split(X_matrix,Y,test_size=0.25,random_state=42)\n",
    "print X_train.shape\n",
    "print X_holdout.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Linear Support Vector Machine Classifier\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  Malignant       0.96      0.98      0.97        89\n",
      "     Benign       0.96      0.93      0.94        54\n",
      "\n",
      "avg / total       0.96      0.96      0.96       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "clf.fit(X_train, Y_train)\n",
    "y_pred = clf.predict(X_holdout)\n",
    "target_names = ['Malignant','Benign']\n",
    "print\"Classification Report for Linear Support Vector Machine Classifier\"\n",
    "print(classification_report(Y_holdout, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes CLassifier Scoring using Cross Validation\n",
      "F1: 0.914\n",
      "Precision: 0.945\n",
      "Recall: 0.885\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb=GaussianNB()\n",
    "\n",
    "print \"Naive Bayes CLassifier Scoring using Cross Validation\"\n",
    "scoremodel(data,nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Naives Bayes Classifier\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  Malignant       0.97      0.97      0.97        89\n",
      "     Benign       0.94      0.94      0.94        54\n",
      "\n",
      "avg / total       0.96      0.96      0.96       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "nb.fit(X_train, Y_train)\n",
    "y_pred_nb = nb.predict(X_holdout)\n",
    "target_names = ['Malignant','Benign']\n",
    "print\"Classification Report for Naives Bayes Classifier\"\n",
    "print(classification_report(Y_holdout, y_pred_nb, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the scores obtained from above, it can be seen that Support vector machines perform better than Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
